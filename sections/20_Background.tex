\section{Spatial Search}
\label{section:background}
Before introducing the data structures and algorithms we use to accomplish spatial search, we define the spatial entities and relations discussed throughout the paper and briefly describe how spatial search queries are specified as input to the spatial search task.
\subsection{Spatial Entities}
\par{
    Spatial entities can be classed into three main types: \textit{Points}, which consist of an $(x,y)$ coordinate pair in Cartesian space, \textit{Lines}, which represent the shortest path between two points, and \textit{Regions}, which represent the area inside a polyline joining several points.                         
        
}


\subsection{Spatial Relations Between Entities}
\par{
     \textit{Points, Lines} and \textit{Regions} relate to each other spatially through the following types of relationships~\cite{Carniel2020,Bertella2022,Carniel2023}:
    \begin{itemize}
        \item \textit{Topological relations} that describe how regions, lines, and points interact (intersect, contain, touch, etc),
        \item \textit{Metric relations} that describe the distances between objects (ten miles, near, far etc.), and
        \item \textit{Directional relations} that describe how objects are positioned relatively in space (north, left, behind etc.).     \end{itemize}

    \textit{Topological} relations are typically binary (e.g., a road intersects another road, or it does not). 
    \textit{Metric} relations can be quickly binned from continuous to discrete values (e.g., a train station is near or far from a house).
    \textit{Directional} relations are typically complex (e.g., a sign, statue, and fountain are arranged in a triangle), making them highly descriptive of the world, at the cost of being challenging to represent.
        The focus of this paper is directional relations between points. 

}

\subsection{Encoding Directional Relations}
\par{
    There are two dominant approaches to encoding directional relations, \textit{space segmentation} and \textit{link encoding}~\cite{Dellapenna2012, Dellapenna2017}.
    \textit{Space segmentation} divides the space around one or many reference point(s), creating a shared list of `objects that are <direction>' of that point. 
    Generalizing space segmentation to capture relations between encoded objects requires each encoded object to act as a reference point, storing the direction of all other objects with respect to it.
     \textit{Link encoding} creates a \textit{Graph} or \textit{Qualitative Constraint Network} (QCN) to explicitly encode pairwise directional relations between objects as links.
    Encoding directional relations requires a fully connected graph or multigraph to capture all the relevant relations.
    Most encoding schemes assume a global coordinate system (e.g., cardinal directions); those that do not are \textit{Cardinality Invariant}.

}


\subsection{Spatial Query Specification}
\par{
    Spatial queries consist of one or more \textit{constraints}.
    Constraints are either \textit{attributes} required of objects in the result set, or spatial relations required between objects in the result set.
    \textit{Attribute constraints} are typically \textit{keywords} that describe the objects of interest like `hospital', `restaurant', or `school'.
    \textit{Relation constraints} are directional relationships like `school West of Pond'.
    Individually encoding these query constraints becomes cumbersome as the number of query objects grows.
        A more natural approach to encoding directional query constraints is to do so implicitly, with a picture or sketch map~\cite{Osul2023}.
    A \textit{pictorial query} accomplishes this using a canvas of points representing query objects configured in a pattern of interest, which implicitly captures the pairwise directional constraints between the objects. 
    
}


\subsection{Spatial Search Task}
\par{
    \textit{Spatial search} is the task of retrieving entities from a database that meet the constraints specified by a spatial query.
    More specifically, spatial pattern matching is a type of \textit{spatial search} that is typically defined as a graph matching problem, where vertices have keyword labels and edges have distance intervals and signs (\textit{exclusion in, exclusion out, mutual exclusion} and \textit{mutual inclusion})~\cite{Fang2019}.
    To address the scalability barrier of spatial pattern matching for directional constraints, we re-frame the problem as a question of satisfiability per location (akin to per graph of objects).
    In other words, instead of retrieving every set of objects meeting the spatial search constraints, we seek to determine \emph{if} a given set of objects associated with a location meets the constraints of the query.
}

















































    
                    
        
                    
                        
            
    
        
            
    %Most SPM methods formulate the problem as a \textit{set-intersection} problem, a \textit{qualitative spatial reasoning} (QSR)/\textit{constraint satisfaction problem} (CSP), or a \textit{subgraph-matching} (SGM) problem, all of which scale poorly with large numbers of relations in the database and constraints in the query. 